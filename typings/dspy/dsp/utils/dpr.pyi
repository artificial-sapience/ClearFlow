from _typeshed import Incomplete

logger: Incomplete

class Tokens:
    TEXT: int
    TEXT_WS: int
    SPAN: int
    POS: int
    LEMMA: int
    NER: int
    data: Incomplete
    annotators: Incomplete
    opts: Incomplete
    def __init__(self, data, annotators, opts=None) -> None: ...
    def __len__(self) -> int: ...
    def slice(self, i=None, j=None): ...
    def untokenize(self): ...
    def words(self, uncased: bool = False): ...
    def offsets(self): ...
    def pos(self): ...
    def lemmas(self): ...
    def entities(self): ...
    def ngrams(self, n: int = 1, uncased: bool = False, filter_fn=None, as_strings: bool = True): ...
    def entity_groups(self): ...

class Tokenizer:
    def tokenize(self, text) -> None: ...
    def shutdown(self) -> None: ...
    def __del__(self) -> None: ...

class SimpleTokenizer(Tokenizer):
    ALPHA_NUM: str
    NON_WS: str
    annotators: Incomplete
    def __init__(self, **kwargs) -> None: ...
    def tokenize(self, text): ...

def has_answer(tokenized_answers, text): ...
def locate_answers(tokenized_answers, text): ...

STokenizer: Incomplete

def DPR_tokenize(text): ...
def DPR_normalize(text): ...
def strip_accents(text): ...
